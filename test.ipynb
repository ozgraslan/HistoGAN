{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ResidualBlock, Discriminator\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "image = torchvision.transforms.Resize(256)(torchvision.io.read_image(\"face.jpg\").float()).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = ResidualBlock(3, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 128, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = rb(image)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator(7, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0526]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(image.size())\n",
    "d(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.zeros((8,3,256,256))\n",
    "d(test).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64516, 16])\n",
      "torch.Size([16, 4, 3, 3]) torch.Size([8, 16, 254, 254]) torch.Size([8, 4, 256, 256]) torch.Size([8, 36, 64516])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(9)\n",
    "#layer = torch.nn.Linear(1, 4)\n",
    "# layer.weight *= 4 inplace operations on leaf variables does not work\n",
    "\n",
    "con_layer = torch.nn.Conv2d(4,16, kernel_size=3)\n",
    "test = torch.zeros((8,4,256,256))\n",
    "test_unf = torch.nn.functional.unfold(test, (3, 3))\n",
    "weight = torch.randn(size=(16, 4, 3, 3))\n",
    "a = test_unf.transpose(1, 2).matmul(weight.view(weight.size(0), -1).t())\n",
    "print(a.size())\n",
    "print(con_layer.weight.size(), con_layer(test).size(), test.size(), test_unf.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 60, 56])\n",
      "torch.Size([4, 2, 56])\n",
      "torch.Size([4, 2, 7, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.7220e-06)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "unfold = nn.Unfold(kernel_size=(2, 3))\n",
    "input = torch.randn(2, 5, 3, 4)\n",
    "output = unfold(input)\n",
    "# each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n",
    "# 4 blocks (2x3 kernels) in total in the 3x4 input\n",
    "# print(input.size(),output.size())\n",
    "\n",
    "# Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n",
    "inp = torch.randn(4, 3, 10, 12)\n",
    "w = torch.randn(2, 3, 4, 5)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n",
    "print(inp_unf.size())\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "print(out_unf.size())\n",
    "out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))\n",
    "print(out.size())\n",
    "# or equivalently (and avoiding a copy),\n",
    "# out = out_unf.view(1, 2, 7, 8)\n",
    "(torch.nn.functional.conv2d(inp, w) - out).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.view(w.size(0), -1).t().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9)\n",
    "def convolution(i, w):\n",
    "\n",
    "    inp_unf = torch.nn.functional.unfold(i, (w.size(2), w.size(3)))\n",
    "    if len(w.size()) == 4:\n",
    "        out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "    else:\n",
    "        print(\"heuy\", inp_unf.transpose(1, 2).size(), w.view(w.size(0), w.size(1), -1).transpose(1,2).size())\n",
    "        out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), w.size(1), -1).transpose(1,2)).transpose(1, 2)\n",
    "    out = torch.nn.functional.fold(out_unf, (i.size(2)-w.size(2)+1, i.size(3)-w.size(3)+1), (1, 1))\n",
    "    print(out.size())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 4, 4])\n",
      "tensor([[[[13.7770, 13.7770, 13.7770, 13.7770],\n",
      "          [13.7770, 13.7770, 13.7770, 13.7770],\n",
      "          [13.7770, 13.7770, 13.7770, 13.7770],\n",
      "          [13.7770, 13.7770, 13.7770, 13.7770]],\n",
      "\n",
      "         [[13.0996, 13.0996, 13.0996, 13.0996],\n",
      "          [13.0996, 13.0996, 13.0996, 13.0996],\n",
      "          [13.0996, 13.0996, 13.0996, 13.0996],\n",
      "          [13.0996, 13.0996, 13.0996, 13.0996]],\n",
      "\n",
      "         [[12.6039, 12.6039, 12.6039, 12.6039],\n",
      "          [12.6039, 12.6039, 12.6039, 12.6039],\n",
      "          [12.6039, 12.6039, 12.6039, 12.6039],\n",
      "          [12.6039, 12.6039, 12.6039, 12.6039]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[12.2737, 12.2737, 12.2737, 12.2737],\n",
      "          [12.2737, 12.2737, 12.2737, 12.2737],\n",
      "          [12.2737, 12.2737, 12.2737, 12.2737],\n",
      "          [12.2737, 12.2737, 12.2737, 12.2737]],\n",
      "\n",
      "         [[11.6748, 11.6748, 11.6748, 11.6748],\n",
      "          [11.6748, 11.6748, 11.6748, 11.6748],\n",
      "          [11.6748, 11.6748, 11.6748, 11.6748],\n",
      "          [11.6748, 11.6748, 11.6748, 11.6748]],\n",
      "\n",
      "         [[13.0647, 13.0647, 13.0647, 13.0647],\n",
      "          [13.0647, 13.0647, 13.0647, 13.0647],\n",
      "          [13.0647, 13.0647, 13.0647, 13.0647],\n",
      "          [13.0647, 13.0647, 13.0647, 13.0647]]],\n",
      "\n",
      "\n",
      "        [[[24.4750, 24.4750, 24.4750, 24.4750],\n",
      "          [24.4750, 24.4750, 24.4750, 24.4750],\n",
      "          [24.4750, 24.4750, 24.4750, 24.4750],\n",
      "          [24.4750, 24.4750, 24.4750, 24.4750]],\n",
      "\n",
      "         [[23.7976, 23.7976, 23.7976, 23.7976],\n",
      "          [23.7976, 23.7976, 23.7976, 23.7976],\n",
      "          [23.7976, 23.7976, 23.7976, 23.7976],\n",
      "          [23.7976, 23.7976, 23.7976, 23.7976]],\n",
      "\n",
      "         [[23.3020, 23.3020, 23.3020, 23.3020],\n",
      "          [23.3020, 23.3020, 23.3020, 23.3020],\n",
      "          [23.3020, 23.3020, 23.3020, 23.3020],\n",
      "          [23.3020, 23.3020, 23.3020, 23.3020]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[22.9717, 22.9717, 22.9717, 22.9717],\n",
      "          [22.9717, 22.9717, 22.9717, 22.9717],\n",
      "          [22.9717, 22.9717, 22.9717, 22.9717],\n",
      "          [22.9717, 22.9717, 22.9717, 22.9717]],\n",
      "\n",
      "         [[22.3728, 22.3728, 22.3728, 22.3728],\n",
      "          [22.3728, 22.3728, 22.3728, 22.3728],\n",
      "          [22.3728, 22.3728, 22.3728, 22.3728],\n",
      "          [22.3728, 22.3728, 22.3728, 22.3728]],\n",
      "\n",
      "         [[23.7627, 23.7627, 23.7627, 23.7627],\n",
      "          [23.7627, 23.7627, 23.7627, 23.7627],\n",
      "          [23.7627, 23.7627, 23.7627, 23.7627],\n",
      "          [23.7627, 23.7627, 23.7627, 23.7627]]],\n",
      "\n",
      "\n",
      "        [[[15.1857, 15.1857, 15.1857, 15.1857],\n",
      "          [15.1857, 15.1857, 15.1857, 15.1857],\n",
      "          [15.1857, 15.1857, 15.1857, 15.1857],\n",
      "          [15.1857, 15.1857, 15.1857, 15.1857]],\n",
      "\n",
      "         [[14.5083, 14.5083, 14.5083, 14.5083],\n",
      "          [14.5083, 14.5083, 14.5083, 14.5083],\n",
      "          [14.5083, 14.5083, 14.5083, 14.5083],\n",
      "          [14.5083, 14.5083, 14.5083, 14.5083]],\n",
      "\n",
      "         [[14.0126, 14.0126, 14.0126, 14.0126],\n",
      "          [14.0126, 14.0126, 14.0126, 14.0126],\n",
      "          [14.0126, 14.0126, 14.0126, 14.0126],\n",
      "          [14.0126, 14.0126, 14.0126, 14.0126]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[13.6824, 13.6824, 13.6824, 13.6824],\n",
      "          [13.6824, 13.6824, 13.6824, 13.6824],\n",
      "          [13.6824, 13.6824, 13.6824, 13.6824],\n",
      "          [13.6824, 13.6824, 13.6824, 13.6824]],\n",
      "\n",
      "         [[13.0835, 13.0835, 13.0835, 13.0835],\n",
      "          [13.0835, 13.0835, 13.0835, 13.0835],\n",
      "          [13.0835, 13.0835, 13.0835, 13.0835],\n",
      "          [13.0835, 13.0835, 13.0835, 13.0835]],\n",
      "\n",
      "         [[14.4733, 14.4733, 14.4733, 14.4733],\n",
      "          [14.4733, 14.4733, 14.4733, 14.4733],\n",
      "          [14.4733, 14.4733, 14.4733, 14.4733],\n",
      "          [14.4733, 14.4733, 14.4733, 14.4733]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[12.9971, 12.9971, 12.9971, 12.9971],\n",
      "          [12.9971, 12.9971, 12.9971, 12.9971],\n",
      "          [12.9971, 12.9971, 12.9971, 12.9971],\n",
      "          [12.9971, 12.9971, 12.9971, 12.9971]],\n",
      "\n",
      "         [[12.3197, 12.3197, 12.3197, 12.3197],\n",
      "          [12.3197, 12.3197, 12.3197, 12.3197],\n",
      "          [12.3197, 12.3197, 12.3197, 12.3197],\n",
      "          [12.3197, 12.3197, 12.3197, 12.3197]],\n",
      "\n",
      "         [[11.8240, 11.8240, 11.8240, 11.8240],\n",
      "          [11.8240, 11.8240, 11.8240, 11.8240],\n",
      "          [11.8240, 11.8240, 11.8240, 11.8240],\n",
      "          [11.8240, 11.8240, 11.8240, 11.8240]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[11.4938, 11.4938, 11.4938, 11.4938],\n",
      "          [11.4938, 11.4938, 11.4938, 11.4938],\n",
      "          [11.4938, 11.4938, 11.4938, 11.4938],\n",
      "          [11.4938, 11.4938, 11.4938, 11.4938]],\n",
      "\n",
      "         [[10.8949, 10.8949, 10.8949, 10.8949],\n",
      "          [10.8949, 10.8949, 10.8949, 10.8949],\n",
      "          [10.8949, 10.8949, 10.8949, 10.8949],\n",
      "          [10.8949, 10.8949, 10.8949, 10.8949]],\n",
      "\n",
      "         [[12.2848, 12.2848, 12.2848, 12.2848],\n",
      "          [12.2848, 12.2848, 12.2848, 12.2848],\n",
      "          [12.2848, 12.2848, 12.2848, 12.2848],\n",
      "          [12.2848, 12.2848, 12.2848, 12.2848]]],\n",
      "\n",
      "\n",
      "        [[[16.8032, 16.8032, 16.8032, 16.8032],\n",
      "          [16.8032, 16.8032, 16.8032, 16.8032],\n",
      "          [16.8032, 16.8032, 16.8032, 16.8032],\n",
      "          [16.8032, 16.8032, 16.8032, 16.8032]],\n",
      "\n",
      "         [[16.1258, 16.1258, 16.1258, 16.1258],\n",
      "          [16.1258, 16.1258, 16.1258, 16.1258],\n",
      "          [16.1258, 16.1258, 16.1258, 16.1258],\n",
      "          [16.1258, 16.1258, 16.1258, 16.1258]],\n",
      "\n",
      "         [[15.6302, 15.6302, 15.6302, 15.6302],\n",
      "          [15.6302, 15.6302, 15.6302, 15.6302],\n",
      "          [15.6302, 15.6302, 15.6302, 15.6302],\n",
      "          [15.6302, 15.6302, 15.6302, 15.6302]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.3000, 15.3000, 15.3000, 15.3000],\n",
      "          [15.3000, 15.3000, 15.3000, 15.3000],\n",
      "          [15.3000, 15.3000, 15.3000, 15.3000],\n",
      "          [15.3000, 15.3000, 15.3000, 15.3000]],\n",
      "\n",
      "         [[14.7011, 14.7011, 14.7011, 14.7011],\n",
      "          [14.7011, 14.7011, 14.7011, 14.7011],\n",
      "          [14.7011, 14.7011, 14.7011, 14.7011],\n",
      "          [14.7011, 14.7011, 14.7011, 14.7011]],\n",
      "\n",
      "         [[16.0909, 16.0909, 16.0909, 16.0909],\n",
      "          [16.0909, 16.0909, 16.0909, 16.0909],\n",
      "          [16.0909, 16.0909, 16.0909, 16.0909],\n",
      "          [16.0909, 16.0909, 16.0909, 16.0909]]],\n",
      "\n",
      "\n",
      "        [[[23.0145, 23.0145, 23.0145, 23.0145],\n",
      "          [23.0145, 23.0145, 23.0145, 23.0145],\n",
      "          [23.0145, 23.0145, 23.0145, 23.0145],\n",
      "          [23.0145, 23.0145, 23.0145, 23.0145]],\n",
      "\n",
      "         [[22.3371, 22.3371, 22.3371, 22.3371],\n",
      "          [22.3371, 22.3371, 22.3371, 22.3371],\n",
      "          [22.3371, 22.3371, 22.3371, 22.3371],\n",
      "          [22.3371, 22.3371, 22.3371, 22.3371]],\n",
      "\n",
      "         [[21.8415, 21.8415, 21.8415, 21.8415],\n",
      "          [21.8415, 21.8415, 21.8415, 21.8415],\n",
      "          [21.8415, 21.8415, 21.8415, 21.8415],\n",
      "          [21.8415, 21.8415, 21.8415, 21.8415]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[21.5112, 21.5112, 21.5112, 21.5112],\n",
      "          [21.5112, 21.5112, 21.5112, 21.5112],\n",
      "          [21.5112, 21.5112, 21.5112, 21.5112],\n",
      "          [21.5112, 21.5112, 21.5112, 21.5112]],\n",
      "\n",
      "         [[20.9124, 20.9124, 20.9124, 20.9124],\n",
      "          [20.9124, 20.9124, 20.9124, 20.9124],\n",
      "          [20.9124, 20.9124, 20.9124, 20.9124],\n",
      "          [20.9124, 20.9124, 20.9124, 20.9124]],\n",
      "\n",
      "         [[22.3022, 22.3022, 22.3022, 22.3022],\n",
      "          [22.3022, 22.3022, 22.3022, 22.3022],\n",
      "          [22.3022, 22.3022, 22.3022, 22.3022],\n",
      "          [22.3022, 22.3022, 22.3022, 22.3022]]]])\n",
      "torch.Size([8, 16, 3, 3, 3])\n",
      "heuy torch.Size([8, 16, 27]) torch.Size([8, 27, 16])\n",
      "torch.Size([8, 16, 4, 4])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(9)\n",
    "i = torch.ones((8,3,6,6))\n",
    "s2 = torch.rand(8,1,3,1,1)\n",
    "s1 = s2.view(8,3,1,1)\n",
    "# print(s)\n",
    "w = torch.ones((16, 3, 3, 3))\n",
    "o1 = convolution(i*s1, w)\n",
    "bias = torch.randn((16,1,1))\n",
    "print(o1+bias)\n",
    "print((s2*w).size())\n",
    "o2 = convolution(i, s2*w)\n",
    "print((~(torch.abs(o1-o2) <1e-3)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((8,3,2,1,1))\n",
    "a.square().sum(dim=(2,3,4), keepdim=True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[ 0.9826]],\n",
       " \n",
       "           [[ 1.3936]]],\n",
       " \n",
       " \n",
       "          [[[-0.5419]],\n",
       " \n",
       "           [[-0.4245]]],\n",
       " \n",
       " \n",
       "          [[[ 0.4435]],\n",
       " \n",
       "           [[-0.5365]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[-1.4623]],\n",
       " \n",
       "           [[-0.8552]]],\n",
       " \n",
       " \n",
       "          [[[ 1.7615]],\n",
       " \n",
       "           [[ 0.0027]]],\n",
       " \n",
       " \n",
       "          [[[ 1.0803]],\n",
       " \n",
       "           [[-1.9376]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[-0.5748]],\n",
       " \n",
       "           [[ 0.4349]]],\n",
       " \n",
       " \n",
       "          [[[-1.6585]],\n",
       " \n",
       "           [[ 1.2364]]],\n",
       " \n",
       " \n",
       "          [[[ 1.2487]],\n",
       " \n",
       "           [[-0.7758]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[-0.6506]],\n",
       " \n",
       "           [[ 1.0455]]],\n",
       " \n",
       " \n",
       "          [[[ 0.9524]],\n",
       " \n",
       "           [[ 1.4272]]],\n",
       " \n",
       " \n",
       "          [[[ 0.2012]],\n",
       " \n",
       "           [[-0.9011]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[-0.1297]],\n",
       " \n",
       "           [[ 1.0740]]],\n",
       " \n",
       " \n",
       "          [[[-0.7193]],\n",
       " \n",
       "           [[ 1.0961]]],\n",
       " \n",
       " \n",
       "          [[[-0.1835]],\n",
       " \n",
       "           [[ 0.7050]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[-1.0667]],\n",
       " \n",
       "           [[ 0.2605]]],\n",
       " \n",
       " \n",
       "          [[[-0.5587]],\n",
       " \n",
       "           [[-0.7631]]],\n",
       " \n",
       " \n",
       "          [[[ 0.9615]],\n",
       " \n",
       "           [[-0.4455]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[-1.0621]],\n",
       " \n",
       "           [[ 0.2867]]],\n",
       " \n",
       " \n",
       "          [[[ 0.1153]],\n",
       " \n",
       "           [[ 0.9901]]],\n",
       " \n",
       " \n",
       "          [[[-0.8335]],\n",
       " \n",
       "           [[-0.0615]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[-0.9855]],\n",
       " \n",
       "           [[ 0.2620]]],\n",
       " \n",
       " \n",
       "          [[[ 1.3328]],\n",
       " \n",
       "           [[ 0.0801]]],\n",
       " \n",
       " \n",
       "          [[[-0.0780]],\n",
       " \n",
       "           [[ 1.8654]]]]]),\n",
       " tensor([[2.9075, 0.4739, 0.4846],\n",
       "         [2.8697, 3.1029, 4.9215],\n",
       "         [0.5196, 4.2794, 2.1611],\n",
       "         [1.5164, 2.9441, 0.8525],\n",
       "         [1.1704, 1.7188, 0.5307],\n",
       "         [1.2057, 0.8945, 1.1230],\n",
       "         [1.2103, 0.9936, 0.6985],\n",
       "         [1.0399, 1.7827, 3.4860]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,a.square().sum(dim=(2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 3, 3, 3])\n",
      "torch.Size([8, 16, 1, 1, 1])\n",
      "torch.Size([8, 16, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 256, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import ModDemodConv3x3\n",
    "mdconv = ModDemodConv3x3(3, 16)\n",
    "i = torch.ones((8,3,256,256))\n",
    "s = torch.rand(8,3)\n",
    "o=mdconv(i,s)\n",
    "o.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 4, 4])\n",
      "torch.Size([1, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)\n",
    "print(input.size())\n",
    "\n",
    "m = torch.nn.Upsample(scale_factor=2, mode='nearest')\n",
    "print(m(input).size())\n",
    "\n",
    "m = torch.nn.Upsample(scale_factor=2, mode='bilinear')  \n",
    "print(m(input).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8917/2440618851.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# -1 means not changing the size of that dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1], [2], [3]])\n",
    "print(x.size())\n",
    "print(x.repeat(4).size())   # -1 means not changing the size of that dimension\n",
    "print(x, x.repeat(1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scaling_factor = torch.tensor([2])\n",
    "noise = torch.randn((1,1,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.5647, -1.3814, -1.1341,  0.3085],\n",
       "           [-0.7618,  0.3484,  1.7113,  1.5437],\n",
       "           [-0.7767, -0.6729, -0.3932,  0.7823],\n",
       "           [-0.5935,  0.7784, -0.1440,  0.5170]]]]),\n",
       " tensor([[[[ 1.1293, -2.7628, -2.2682,  0.6170],\n",
       "           [-1.5236,  0.6969,  3.4226,  3.0875],\n",
       "           [-1.5533, -1.3458, -0.7864,  1.5645],\n",
       "           [-1.1869,  1.5568, -0.2881,  1.0340]]]]),\n",
       " torch.Size([1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise, noise_scaling_factor * noise, noise_scaling_factor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., -0., -0., 0.],\n",
       "          [-0., 0., 0., 0.],\n",
       "          [-0., -0., -0., 0.],\n",
       "          [-0., 0., -0., 0.]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1))*noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 4, 4]), torch.Size([8, 3, 8, 8]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsample = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")\n",
    "inp = torch.randn(8,3,4,4)\n",
    "inp.size(), upsample(inp).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = torch.nn.Conv2d(3,16,3)\n",
    "layer.weight.size(), layer.bias.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((8,3,16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 14, 14])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(inp).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import HistoGAN\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0432, -0.0432, -0.0433,  ...,  0.0757,  0.0756,  0.0755],\n",
       "          [-0.0433, -0.0433, -0.0434,  ...,  0.0758,  0.0756,  0.0755],\n",
       "          [-0.0434, -0.0434, -0.0434,  ...,  0.0759,  0.0757,  0.0756],\n",
       "          ...,\n",
       "          [-0.2644, -0.2643, -0.2640,  ..., -0.3863, -0.3868, -0.3870],\n",
       "          [-0.2646, -0.2644, -0.2641,  ..., -0.3867, -0.3872, -0.3874],\n",
       "          [-0.2647, -0.2645, -0.2642,  ..., -0.3870, -0.3874, -0.3876]],\n",
       "\n",
       "         [[-0.0469, -0.0468, -0.0466,  ...,  0.0352,  0.0357,  0.0360],\n",
       "          [-0.0470, -0.0468, -0.0466,  ...,  0.0353,  0.0358,  0.0361],\n",
       "          [-0.0470, -0.0469, -0.0466,  ...,  0.0356,  0.0361,  0.0363],\n",
       "          ...,\n",
       "          [ 0.2016,  0.2017,  0.2018,  ..., -0.2117, -0.2118, -0.2118],\n",
       "          [ 0.2022,  0.2023,  0.2024,  ..., -0.2118, -0.2119, -0.2120],\n",
       "          [ 0.2025,  0.2026,  0.2026,  ..., -0.2119, -0.2120, -0.2120]],\n",
       "\n",
       "         [[-0.2190, -0.2191, -0.2192,  ..., -0.2801, -0.2804, -0.2806],\n",
       "          [-0.2191, -0.2192, -0.2193,  ..., -0.2802, -0.2805, -0.2806],\n",
       "          [-0.2193, -0.2194, -0.2195,  ..., -0.2803, -0.2806, -0.2807],\n",
       "          ...,\n",
       "          [-0.0297, -0.0299, -0.0304,  ..., -0.0839, -0.0837, -0.0836],\n",
       "          [-0.0296, -0.0298, -0.0302,  ..., -0.0836, -0.0834, -0.0833],\n",
       "          [-0.0295, -0.0297, -0.0300,  ..., -0.0834, -0.0832, -0.0831]]],\n",
       "\n",
       "\n",
       "        [[[-0.0364, -0.0364, -0.0366,  ...,  0.0747,  0.0745,  0.0744],\n",
       "          [-0.0364, -0.0365, -0.0366,  ...,  0.0748,  0.0746,  0.0744],\n",
       "          [-0.0365, -0.0365, -0.0366,  ...,  0.0749,  0.0746,  0.0745],\n",
       "          ...,\n",
       "          [-0.2584, -0.2582, -0.2579,  ..., -0.3776, -0.3781, -0.3784],\n",
       "          [-0.2585, -0.2584, -0.2580,  ..., -0.3781, -0.3785, -0.3788],\n",
       "          [-0.2586, -0.2584, -0.2581,  ..., -0.3783, -0.3787, -0.3789]],\n",
       "\n",
       "         [[-0.0435, -0.0434, -0.0431,  ...,  0.0432,  0.0437,  0.0440],\n",
       "          [-0.0435, -0.0434, -0.0431,  ...,  0.0433,  0.0438,  0.0441],\n",
       "          [-0.0436, -0.0435, -0.0431,  ...,  0.0436,  0.0441,  0.0443],\n",
       "          ...,\n",
       "          [ 0.1913,  0.1914,  0.1915,  ..., -0.2209, -0.2210, -0.2210],\n",
       "          [ 0.1919,  0.1920,  0.1921,  ..., -0.2211, -0.2211, -0.2212],\n",
       "          [ 0.1922,  0.1923,  0.1924,  ..., -0.2211, -0.2212, -0.2212]],\n",
       "\n",
       "         [[-0.1997, -0.1997, -0.1998,  ..., -0.2712, -0.2715, -0.2717],\n",
       "          [-0.1998, -0.1998, -0.2000,  ..., -0.2713, -0.2716, -0.2718],\n",
       "          [-0.1999, -0.2000, -0.2002,  ..., -0.2714, -0.2717, -0.2718],\n",
       "          ...,\n",
       "          [-0.0381, -0.0383, -0.0388,  ..., -0.0958, -0.0956, -0.0955],\n",
       "          [-0.0380, -0.0382, -0.0385,  ..., -0.0955, -0.0953, -0.0953],\n",
       "          [-0.0379, -0.0381, -0.0384,  ..., -0.0954, -0.0952, -0.0951]]],\n",
       "\n",
       "\n",
       "        [[[-0.0358, -0.0358, -0.0359,  ...,  0.0748,  0.0746,  0.0745],\n",
       "          [-0.0359, -0.0359, -0.0360,  ...,  0.0749,  0.0746,  0.0745],\n",
       "          [-0.0360, -0.0360, -0.0360,  ...,  0.0750,  0.0747,  0.0746],\n",
       "          ...,\n",
       "          [-0.2601, -0.2599, -0.2596,  ..., -0.3739, -0.3745, -0.3747],\n",
       "          [-0.2602, -0.2601, -0.2597,  ..., -0.3745, -0.3749, -0.3751],\n",
       "          [-0.2603, -0.2601, -0.2598,  ..., -0.3747, -0.3751, -0.3754]],\n",
       "\n",
       "         [[-0.0365, -0.0363, -0.0361,  ...,  0.0371,  0.0376,  0.0379],\n",
       "          [-0.0365, -0.0364, -0.0361,  ...,  0.0373,  0.0377,  0.0380],\n",
       "          [-0.0366, -0.0364, -0.0361,  ...,  0.0376,  0.0380,  0.0383],\n",
       "          ...,\n",
       "          [ 0.2068,  0.2069,  0.2070,  ..., -0.2030, -0.2031, -0.2032],\n",
       "          [ 0.2074,  0.2075,  0.2076,  ..., -0.2032, -0.2033, -0.2033],\n",
       "          [ 0.2078,  0.2078,  0.2078,  ..., -0.2032, -0.2033, -0.2034]],\n",
       "\n",
       "         [[-0.2058, -0.2058, -0.2060,  ..., -0.2699, -0.2702, -0.2703],\n",
       "          [-0.2059, -0.2060, -0.2061,  ..., -0.2699, -0.2702, -0.2704],\n",
       "          [-0.2061, -0.2062, -0.2064,  ..., -0.2700, -0.2703, -0.2705],\n",
       "          ...,\n",
       "          [-0.0498, -0.0500, -0.0505,  ..., -0.0942, -0.0941, -0.0940],\n",
       "          [-0.0496, -0.0498, -0.0502,  ..., -0.0940, -0.0938, -0.0937],\n",
       "          [-0.0496, -0.0498, -0.0501,  ..., -0.0938, -0.0936, -0.0935]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0429, -0.0430, -0.0431,  ...,  0.0727,  0.0725,  0.0724],\n",
       "          [-0.0430, -0.0430, -0.0431,  ...,  0.0728,  0.0726,  0.0725],\n",
       "          [-0.0431, -0.0431, -0.0432,  ...,  0.0728,  0.0726,  0.0725],\n",
       "          ...,\n",
       "          [-0.2617, -0.2616, -0.2613,  ..., -0.3749, -0.3754, -0.3756],\n",
       "          [-0.2619, -0.2617, -0.2614,  ..., -0.3754, -0.3758, -0.3761],\n",
       "          [-0.2619, -0.2618, -0.2615,  ..., -0.3757, -0.3761, -0.3763]],\n",
       "\n",
       "         [[-0.0486, -0.0485, -0.0482,  ...,  0.0383,  0.0388,  0.0390],\n",
       "          [-0.0486, -0.0485, -0.0482,  ...,  0.0384,  0.0389,  0.0392],\n",
       "          [-0.0487, -0.0485, -0.0482,  ...,  0.0387,  0.0392,  0.0395],\n",
       "          ...,\n",
       "          [ 0.2132,  0.2132,  0.2134,  ..., -0.2127, -0.2128, -0.2129],\n",
       "          [ 0.2138,  0.2138,  0.2139,  ..., -0.2129, -0.2130, -0.2130],\n",
       "          [ 0.2141,  0.2142,  0.2142,  ..., -0.2129, -0.2130, -0.2131]],\n",
       "\n",
       "         [[-0.2202, -0.2203, -0.2203,  ..., -0.2681, -0.2684, -0.2685],\n",
       "          [-0.2203, -0.2204, -0.2205,  ..., -0.2681, -0.2684, -0.2686],\n",
       "          [-0.2205, -0.2206, -0.2208,  ..., -0.2682, -0.2685, -0.2686],\n",
       "          ...,\n",
       "          [-0.0356, -0.0358, -0.0363,  ..., -0.1005, -0.1003, -0.1002],\n",
       "          [-0.0355, -0.0357, -0.0360,  ..., -0.1002, -0.1000, -0.0999],\n",
       "          [-0.0354, -0.0356, -0.0359,  ..., -0.1000, -0.0998, -0.0997]]],\n",
       "\n",
       "\n",
       "        [[[-0.0323, -0.0323, -0.0324,  ...,  0.0595,  0.0593,  0.0592],\n",
       "          [-0.0323, -0.0324, -0.0324,  ...,  0.0596,  0.0594,  0.0593],\n",
       "          [-0.0324, -0.0324, -0.0325,  ...,  0.0597,  0.0594,  0.0593],\n",
       "          ...,\n",
       "          [-0.2666, -0.2664, -0.2661,  ..., -0.3828, -0.3833, -0.3835],\n",
       "          [-0.2667, -0.2665, -0.2662,  ..., -0.3833, -0.3837, -0.3840],\n",
       "          [-0.2668, -0.2666, -0.2663,  ..., -0.3835, -0.3840, -0.3842]],\n",
       "\n",
       "         [[-0.0460, -0.0459, -0.0456,  ...,  0.0458,  0.0463,  0.0465],\n",
       "          [-0.0460, -0.0459, -0.0456,  ...,  0.0459,  0.0464,  0.0467],\n",
       "          [-0.0461, -0.0459, -0.0456,  ...,  0.0462,  0.0467,  0.0469],\n",
       "          ...,\n",
       "          [ 0.2131,  0.2132,  0.2133,  ..., -0.2121, -0.2122, -0.2123],\n",
       "          [ 0.2137,  0.2138,  0.2138,  ..., -0.2123, -0.2124, -0.2124],\n",
       "          [ 0.2140,  0.2140,  0.2141,  ..., -0.2124, -0.2125, -0.2125]],\n",
       "\n",
       "         [[-0.2241, -0.2241, -0.2242,  ..., -0.2743, -0.2746, -0.2748],\n",
       "          [-0.2242, -0.2242, -0.2243,  ..., -0.2743, -0.2746, -0.2748],\n",
       "          [-0.2244, -0.2244, -0.2246,  ..., -0.2744, -0.2747, -0.2749],\n",
       "          ...,\n",
       "          [-0.0226, -0.0228, -0.0233,  ..., -0.0888, -0.0887, -0.0886],\n",
       "          [-0.0224, -0.0226, -0.0230,  ..., -0.0885, -0.0883, -0.0882],\n",
       "          [-0.0223, -0.0225, -0.0229,  ..., -0.0884, -0.0882, -0.0881]]],\n",
       "\n",
       "\n",
       "        [[[-0.0370, -0.0370, -0.0372,  ...,  0.0670,  0.0668,  0.0667],\n",
       "          [-0.0371, -0.0371, -0.0372,  ...,  0.0670,  0.0668,  0.0667],\n",
       "          [-0.0372, -0.0372, -0.0373,  ...,  0.0671,  0.0669,  0.0668],\n",
       "          ...,\n",
       "          [-0.2657, -0.2655, -0.2652,  ..., -0.3808, -0.3813, -0.3815],\n",
       "          [-0.2659, -0.2657, -0.2654,  ..., -0.3813, -0.3817, -0.3820],\n",
       "          [-0.2660, -0.2658, -0.2655,  ..., -0.3815, -0.3820, -0.3822]],\n",
       "\n",
       "         [[-0.0415, -0.0413, -0.0411,  ...,  0.0536,  0.0541,  0.0543],\n",
       "          [-0.0415, -0.0414, -0.0411,  ...,  0.0537,  0.0542,  0.0544],\n",
       "          [-0.0416, -0.0414, -0.0411,  ...,  0.0540,  0.0544,  0.0547],\n",
       "          ...,\n",
       "          [ 0.1933,  0.1934,  0.1935,  ..., -0.2144, -0.2145, -0.2145],\n",
       "          [ 0.1939,  0.1940,  0.1940,  ..., -0.2145, -0.2146, -0.2146],\n",
       "          [ 0.1942,  0.1943,  0.1943,  ..., -0.2146, -0.2147, -0.2147]],\n",
       "\n",
       "         [[-0.2115, -0.2116, -0.2117,  ..., -0.2823, -0.2826, -0.2827],\n",
       "          [-0.2116, -0.2117, -0.2118,  ..., -0.2823, -0.2826, -0.2827],\n",
       "          [-0.2118, -0.2119, -0.2121,  ..., -0.2824, -0.2827, -0.2828],\n",
       "          ...,\n",
       "          [-0.0353, -0.0355, -0.0360,  ..., -0.0945, -0.0944, -0.0943],\n",
       "          [-0.0352, -0.0353, -0.0357,  ..., -0.0943, -0.0941, -0.0940],\n",
       "          [-0.0351, -0.0353, -0.0356,  ..., -0.0941, -0.0939, -0.0938]]]],\n",
       "       grad_fn=<UpsampleBilinear2DBackward1>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histogan = HistoGAN()\n",
    "z = torch.randn((8,512))\n",
    "img = torch.rand((8,3, 256, 256))\n",
    "_, hist = histogan(z, img)\n",
    "\n",
    "hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f6dd8c1d7576cf0de48aad06b0e935e2de8273eecf0f787202423f6355e44ee"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
