{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper Information\n",
    "The paper we selected to implement is [HistoGAN: Controlling Colors of GAN-Generated and Real Images via Color Histograms](https://arxiv.org/abs/2011.11731)\n",
    "The main idea of the paper is to use color histogram of target images to control the colors of the generated image without changing the high level features of the generated image (gender, having glasses, beard, hair style and objects in the background...)  \n",
    "To accomplish this idea, they modify the StyleGAN2 architecture:\n",
    "- In the last 2 style blocks, instead of using affine transformation of the w vector, they use the color histogram projected by a neural network.\n",
    "- Different from mixing regularization, they use a histogram based loss.\n",
    "- The histogram loss uses two different target images to compute color histograms and interpolate this histograms to obtain a new one. The interpolated histogram is given to generator network to generate a target image with colors controlled by the interpolated histogram. This way the authors try to prevent the generator network to overfit color histograms of the trained dataset.\n",
    "- Due to hardware limitations the network does not generate 1024x1024 resolution images but generates 256x256 images.\n",
    "- Also due to hardware limitations they use batches of size 2 with gradient accumulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
